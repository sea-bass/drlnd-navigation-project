{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banana World Navigation\n",
    "\n",
    "---\n",
    "\n",
    "This is the first project in the Udacity [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893), in which the [Deep Q-Network (DQN) algorithm](https://arxiv.org/abs/1312.5602) is used to solve a simple \"Banana Collector\" game in a [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents) simulation environment.\n",
    "\n",
    "### 1. Import Dependencies\n",
    "\n",
    "We begin by importing some necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment. At each time step, there are 4 possible actions to take:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "The section below will display some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Action size: 4\n",
      "State size: 37\n",
      "Initial state value: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the environment\n",
    "# NOTE: You should change your `env_file` variable below as needed\n",
    "env_file = \"/home/sebastian/udacity_drl/drlnd-navigation-project/Banana_Linux/Banana.x86_64\"\n",
    "env = UnityEnvironment(file_name=env_file)\n",
    "\n",
    "# Get the first \"brain\" available from the environment\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# Reset the environment and collect information\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Action size:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "state_size = len(state)\n",
    "print('State size:', state_size)\n",
    "print('Initial state value:', state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In this section, we will test the simulation with an \"agent\" that selects an action randomly from a uniform distribution. \n",
    "\n",
    "We will use the final reward collected as a benchmark to see if we can do better by training an agent using reinforcement learning (spoiler alert: we can)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with random actions: 2.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "random_score = 0                                   # initialize the score\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action = np.random.randint(action_size)        # select an action at random\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    random_score += reward                         # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    \n",
    "print(\"Score with random actions: {}\".format(random_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build and Train a Deep Q-Network (DQN) Agent\n",
    "\n",
    "#### 4a. Create a Q-Network\n",
    "\n",
    "First we will define a Q-Network model architecture. This neural network will be our trainable function approximator that accepts a state as input and returns an estimate of the state-action value (or Q) for that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a neural network to estimate the state-action value (Q) given an input state.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_states=37, num_actions=4, layer_dims=[128, 64, 32]):\n",
    "        \"\"\"\n",
    "        Initialize the Q-Network structure\n",
    "        \n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_states, layer_dims[0])\n",
    "        self.fc2 = nn.Linear(layer_dims[0], layer_dims[1])\n",
    "        self.fc3 = nn.Linear(layer_dims[1], layer_dims[2])\n",
    "        self.fc4 = nn.Linear(layer_dims[2], num_actions)\n",
    "        \n",
    "        \n",
    "    def forward(self, state):\n",
    "        \"\"\" \n",
    "        Forward pass through the Q-Network, which accepts a state (array_like)\n",
    "        and returns state-action values (float) for each action.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Create a DQN Agent\n",
    "\n",
    "Now, we will create a DQN Agent that can train the Q-Network defined above. This is a standard implementation of the [Deep Q-Network (DQN) algorithm](https://arxiv.org/abs/1312.5602).\n",
    "\n",
    "The general idea is as follows:\n",
    "1. A Deep Q-Network is initialized with some weights\n",
    "2. Using the network with its current weights (plus some exploration strategy), the agent will choose an action which takes it to a new state\n",
    "3. This tuple of (state, action, reward, new_state) will be added to an experience buffer\n",
    "4. At some frequency, the agent will take a training step. This involves sampling a mini-batch at random from the experience buffer (which helps remove correlated experiences) and using the difference between expected and observed state-action values (Q-values) to define a loss function that can help train the network via backpropagation.\n",
    "5. In practice, DQN can be unstable, so the use of a target network is common and part of this implementation. Here, the target network is updated more slowly than the \"local\" network with a rate `tau`. The target network is used during training such that the Q-value targets are not changing at the same rate as the local Q-network is updating is weights, thus minimizing issues from chasing a nonstationary target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Torch compute device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DQNAgent():\n",
    "    \"\"\"\n",
    "    Defines a Deep Q-Network (DQN) Reinforcement Learning Agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, action_size, batch_size=64, gamma=0.99, learn_rate=1e-3, \n",
    "                 learn_period=4, replay_buffer_size=200000, tau=1e-3, seed=0):\n",
    "        \"\"\" \n",
    "        Initialize a Reinforcement Learning Agent \n",
    "        \n",
    "        The first input is the action size (number of actions), which is needed to randomly\n",
    "        sample actions when performing epsilon-greedy exploration.\n",
    "        \n",
    "        All other inputs are optional hyperparameters which are defined later on in this notebook.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Unpack arguments\n",
    "        self.action_size = action_size\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.learn_period = learn_period\n",
    "        self.tau = tau\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        # Define the local and target Q-Networks\n",
    "        self.qnetwork_local = QNetwork().to(device)\n",
    "        self.qnetwork_target = QNetwork().to(device)\n",
    "        \n",
    "        # Define an optimizer for training the Q-Network\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=learn_rate)\n",
    "\n",
    "        # Create a replay buffer\n",
    "        self.replay_buffer = ReplayBuffer(replay_buffer_size, batch_size, seed)\n",
    "        \n",
    "        # Initialize quantities to keep track of\n",
    "        self.t_step = 0\n",
    "        \n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\" \n",
    "        Steps the agent given the results of stepping the RL environment \n",
    "        \n",
    "        Inputs\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            action (int): the action taken at the current state\n",
    "            reward (float): reward received from taking the action at the current state\n",
    "            next_state (array_like): the new state reached after taking the action\n",
    "            done (bool): flag indicating whether the episode is complete \n",
    "        \"\"\"\n",
    "        \n",
    "        # Save the new experience in replay memory\n",
    "        self.replay_buffer.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every `learn_period` time steps.\n",
    "        self.t_step = (self.t_step + 1) % self.learn_period\n",
    "        if self.t_step == 0:\n",
    "            # Sample a subset of experiences from the replay buffer \n",
    "            # as soon as there are enough experiences to fill a batch\n",
    "            if len(self.replay_buffer) >= self.batch_size:\n",
    "                batch = self.replay_buffer.sample()\n",
    "                self.learn(batch)\n",
    "               \n",
    "\n",
    "    def get_action(self, state, epsilon):\n",
    "        \"\"\"\n",
    "        Returns actions for given state as per current policy.\n",
    "        \n",
    "        Inputs\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        \n",
    "        # Run a forward pass of the Q-Network given an input state\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > epsilon:\n",
    "            action = np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            action = random.choice(np.arange(self.action_size))\n",
    "        \n",
    "        return action\n",
    "        \n",
    "\n",
    "    def learn(self, experiences):\n",
    "        \"\"\"\n",
    "        Update value parameters using given batch of experience tuples.\n",
    "        \n",
    "        Inputs\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (self.gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute and minimize the loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Finally, update the target networks using the new parameters after the training step\n",
    "        self.soft_update()\n",
    "        \n",
    "\n",
    "    def soft_update(self):\n",
    "        \"\"\"\n",
    "        Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        \n",
    "        Inputs\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(self.qnetwork_target.parameters(), self.qnetwork_local.parameters()):\n",
    "            target_param.data.copy_(self.tau*local_param.data + (1.0-self.tau)*target_param.data)\n",
    "\n",
    "            \n",
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    Fixed-size buffer to store experience tuples for reinforcement learning\n",
    "    This replay buffer implementation is directly from the following source:\n",
    "    https://github.com/udacity/deep-reinforcement-learning/blob/master/dqn/solution/dqn_agent.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size, batch_size, seed):\n",
    "        \"\"\"\n",
    "        Initialize a ReplayBuffer object.\n",
    "        \n",
    "        Inputs\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Train the Agent\n",
    "\n",
    "Now that we have defined Q-Network and DQN Agent classes, we can train on the environment. The general steps are:\n",
    "\n",
    "1. Define hyperparameters\n",
    "2. Train the agent by running several episodes\n",
    "3. Save the final network weights to a faile\n",
    "\n",
    "You can opt to skip training and load our pretrained network weights by setting the `do_train` variable below to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score at episode 1: 2.0\n",
      "Average score at episode 101: 0.44\n",
      "Average score at episode 201: 3.22\n",
      "Average score at episode 301: 8.09\n",
      "Average score at episode 401: 10.96\n",
      "Average score at episode 501: 14.08\n",
      "Average score at episode 601: 15.25\n",
      "Average score at episode 701: 15.49\n",
      "Average score at episode 801: 15.85\n",
      "Average score at episode 901: 15.3\n",
      "Average score at episode 1001: 16.18\n",
      "Average score at episode 1101: 16.04\n",
      "Average score at episode 1201: 15.86\n",
      "Average score at episode 1301: 16.24\n",
      "Average score at episode 1401: 15.91\n",
      "Average score at episode 1501: 16.62\n",
      "Average score at episode 1601: 16.11\n",
      "Average score at episode 1701: 15.68\n",
      "Average score at episode 1801: 15.85\n",
      "Average score at episode 1901: 15.72\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_train = True\n",
    "\n",
    "#######################\n",
    "### HYPERPARAMETERS ###\n",
    "#######################\n",
    "# As you can see, it takes a village of hyperparameters to get many RL algorithms working well\n",
    "\n",
    "# Training parameters\n",
    "NUM_EPISODES = 2000         # Total number of episodes to train\n",
    "AVERAGE_WINDOW = 100        # Number of episodes to compute average reward\n",
    "MAX_EPISODE_STEPS = 10000   # Maximum number of steps per episode\n",
    "LEARN_PERIOD = 4            # Number of simulation steps between running a training step\n",
    "BATCH_SIZE = 64             # Training batch size (sampled from replay buffer)\n",
    "REPLAY_BUFFER_SIZE = 200000 # Number of experiences in replay buffer for sampling at training time\n",
    "\n",
    "# Reinforcement Learning parameters\n",
    "GAMMA = 0.999               # Discount factor\n",
    "TAU = 1e-3                  # Update rate for the target network\n",
    "\n",
    "# Learning rate parameters\n",
    "LEARN_RATE = 1e-3               # Base learning rate\n",
    "LEARN_RATE_DECAY_FACTOR = 0.25  # Stepwise factor for learning rate\n",
    "LEARN_RATE_DECAY_PERIOD = 500   # Number of episodes before stepping down learning rate\n",
    "\n",
    "# Exploration vs. exploitation parameters (epsilon = probability of randomly picking action)\n",
    "EPS_INIT = 0.5                            # Initial value of epsilon\n",
    "EPS_FINAL = 0.05                          # Final (and minimum) value of epsilon\n",
    "EPS_DECAY_STEPS = int(0.9*NUM_EPISODES)   # Number of episodes over which epsilon is linearly decayed to its minimum\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "### END HYPERPARAMETERS ###\n",
    "\n",
    "\n",
    "# Create the agent and learning rate decay scheduler\n",
    "agent = DQNAgent(action_size=action_size, learn_rate=LEARN_RATE, learn_period=LEARN_PERIOD, \n",
    "                 batch_size=BATCH_SIZE, replay_buffer_size=REPLAY_BUFFER_SIZE,\n",
    "                 gamma=GAMMA, tau=TAU, seed=RANDOM_SEED)\n",
    "lr_decay = optim.lr_scheduler.StepLR(agent.optimizer, \n",
    "    step_size=LEARN_RATE_DECAY_PERIOD, gamma=LEARN_RATE_DECAY_FACTOR)\n",
    "\n",
    "# Train the agent\n",
    "if do_train:\n",
    "    epsilon = EPS_INIT\n",
    "    scores = []\n",
    "    scores_avg = []\n",
    "    scores_window = deque(maxlen=AVERAGE_WINDOW)\n",
    "    for idx in range(NUM_EPISODES):\n",
    "\n",
    "        # Start the episode by resetting the environment\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        done = False\n",
    "        score = 0\n",
    "\n",
    "        # Run the episode to completion\n",
    "        t_step = 0\n",
    "        while not done:\n",
    "            # Get the next action from the agent using the epsilon-greedy policy\n",
    "            action = agent.get_action(state, epsilon)\n",
    "\n",
    "            # Step the environment and unpack the information\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            reward = env_info.rewards[0]\n",
    "            done = env_info.local_done[0] \n",
    "\n",
    "            # Step the agent and learning rate scheduler\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "\n",
    "            # Update the next state and score\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            t_step += 1\n",
    "            if t_step >= MAX_EPISODE_STEPS:\n",
    "                break\n",
    "\n",
    "        # Once the episode is done, decay epsilon and learning rate\n",
    "        epsilon = max(EPS_FINAL, epsilon - (EPS_INIT-EPS_FINAL)*(idx/EPS_DECAY_STEPS))\n",
    "        lr_decay.step()\n",
    "\n",
    "        # Update the average scores\n",
    "        scores.append(score)\n",
    "        scores_window.append(score)\n",
    "        if idx % AVERAGE_WINDOW == 0:\n",
    "            mean_score = np.mean(scores_window)\n",
    "            scores_avg.append(mean_score)\n",
    "            print(\"\\rAverage score at episode {}: {}\".format(idx, mean_score))\n",
    "\n",
    "    ### End training loop ###\n",
    "            \n",
    "    # Plot the final scores\n",
    "    fig = plt.figure()\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.plot(np.arange(len(scores_avg))*AVERAGE_WINDOW, scores_avg)\n",
    "    plt.xlabel(\"Episode number\")\n",
    "    plt.ylabel(\"Total reward\")\n",
    "    plt.legend([\"Raw scores\", \"Average scores\"])\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the trained agent to file\n",
    "    torch.save(agent.qnetwork_local.state_dict(),\"trained_weights.pth\")\n",
    "\n",
    "# Else load a pretrained model\n",
    "else:\n",
    "    trained_agent = torch.load(\"trained_weights.pth\")\n",
    "    agent.qnetwork_local.load_state_dict(trained_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the Trained Agent\n",
    "\n",
    "Now we will run the environment with the trained agent using a fully greedy policy (epsilon=0) and compare it to the earlier run in which the agent took purely random actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with random agent: 0.0\n",
      "Score with trained agent: 17.0\n"
     ]
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "state = env_info.vector_observations[0]\n",
    "score = 0\n",
    "\n",
    "# Run the trained agent until the end of the episode\n",
    "done = False\n",
    "while not done:\n",
    "    # Get an action with the agent, using the fully greedy policy\n",
    "    action = agent.get_action(state, 0)            \n",
    "    \n",
    "    # Then, step the agent using this action\n",
    "    env_info = env.step(action)[brain_name]\n",
    "    next_state = env_info.vector_observations[0]\n",
    "    reward = env_info.rewards[0]\n",
    "    done = env_info.local_done[0]\n",
    "    score += reward\n",
    "    state = next_state\n",
    "    \n",
    "# Now compare the final scores with random actions and with the trained agent\n",
    "print(\"Score with random agent: {}\".format(random_score))\n",
    "print(\"Score with trained agent: {}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
